{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pyspark\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.functions import min, max, col, count, array\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler, VectorSizeHint, StringIndexer, ChiSqSelector\n",
    "from pyspark.ml.clustering import KMeans, BisectingKMeans\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.inMemoryColumnarStorage.compressed\", True)\n",
    "spark.conf.set(\"spark.sql.inMemoryColumnarStorage.batchSize\",10000)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json('medium-sparkify-event-data.json')\n",
    "df = df.withColumn('sessionId', col('sessionId').cast('int')) \\\n",
    "    .withColumn('ts', col('ts').cast('int')).dropDuplicates()\n",
    "df = df.filter(df.userId != \"\").persist()\n",
    "ac = df.columns\n",
    "train_data, test_data = df.randomSplit([.9999, .0001], seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = test_data.randomSplit([.8,.2],seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------------\n",
      " artist        | null                 \n",
      " auth          | Logged In            \n",
      " firstName     | Allisson             \n",
      " gender        | F                    \n",
      " itemInSession | 121                  \n",
      " lastName      | Oneill               \n",
      " length        | null                 \n",
      " level         | paid                 \n",
      " location      | Mansfield, OH        \n",
      " method        | PUT                  \n",
      " page          | Add Friend           \n",
      " registration  | 1532260956000        \n",
      " sessionId     | 2757                 \n",
      " song          | null                 \n",
      " status        | 307                  \n",
      " ts            | 1039871736           \n",
      " userAgent     | Mozilla/5.0 (X11;... \n",
      " userId        | 204                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.show(1, vertical = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = []\n",
    "for each in paid.columns:\n",
    "    col_names.append(each + \"Index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexer = StringIndexer(inputCols = paid.columns, outputCols = col_names, handleInvalid = 'skip')\n",
    "vecAssembler = VectorAssembler(inputCols=col_names, outputCol = 'features')\n",
    "css = ChiSqSelector(featuresCol = 'features', outputCol=\"selectedFeatures\", labelCol = 'sessionId', fpr = 0.05)\n",
    "lr = LogisticRegression(labelCol = \"levelIndex\", featuresCol = \"selectedFeatures\", predictionCol = 'prediction', \\\n",
    "                        rawPredictionCol = 'rawPrediction', maxIter = 10)\n",
    "pipeline = Pipeline(stages = [indexer, vecAssembler, css, lr])\n",
    "\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='levelIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------\n",
      " artist             | Santigold            \n",
      " auth               | Logged In            \n",
      " firstName          | Kaelyn               \n",
      " gender             | F                    \n",
      " itemInSession      | 96                   \n",
      " lastName           | Parker               \n",
      " length             | 234.91873            \n",
      " level              | paid                 \n",
      " location           | Sioux Falls, SD      \n",
      " method             | PUT                  \n",
      " page               | NextSong             \n",
      " registration       | 1531320812000        \n",
      " sessionId          | 1421                 \n",
      " song               | Starstruck           \n",
      " status             | 200                  \n",
      " ts                 | -2009606264          \n",
      " userAgent          | Mozilla/5.0 (X11;... \n",
      " userId             | 184                  \n",
      " lengthIndex        | 22.0                 \n",
      " firstNameIndex     | 32.0                 \n",
      " lastNameIndex      | 29.0                 \n",
      " userAgentIndex     | 24.0                 \n",
      " tsIndex            | 9.0                  \n",
      " itemInSessionIndex | 4.0                  \n",
      " pageIndex          | 0.0                  \n",
      " methodIndex        | 0.0                  \n",
      " songIndex          | 34.0                 \n",
      " levelIndex         | 0.0                  \n",
      " genderIndex        | 1.0                  \n",
      " userIdIndex        | 19.0                 \n",
      " registrationIndex  | 7.0                  \n",
      " artistIndex        | 33.0                 \n",
      " sessionIdIndex     | 7.0                  \n",
      " locationIndex      | 36.0                 \n",
      " authIndex          | 0.0                  \n",
      " statusIndex        | 0.0                  \n",
      " features           | [33.0,0.0,32.0,1.... \n",
      " selectedFeatures   | [33.0,0.0,32.0,1.... \n",
      " rawPrediction      | [9.12961165811446... \n",
      " probability        | [0.99989160407478... \n",
      " prediction         | 0.0                  \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_data = pipeline.fit(train_data).transform(train_data)\n",
    "tr_data.show(1, vertical = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_data = pipeline.fit(test_data).transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+--------------------+\n",
      "|levelIndex|       rawPrediction|prediction|         probability|\n",
      "+----------+--------------------+----------+--------------------+\n",
      "|       0.0|[9.12961165811446...|       0.0|[0.99989160407478...|\n",
      "|       0.0|[9.81440319670280...|       0.0|[0.99994534434400...|\n",
      "|       1.0|[-10.679374866924...|       1.0|[2.30142289937649...|\n",
      "|       0.0|[8.73824161721772...|       0.0|[0.99983969013188...|\n",
      "|       1.0|[-11.145114341387...|       1.0|[1.44454830065698...|\n",
      "+----------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_data.select('levelIndex', 'rawPrediction', 'prediction', 'probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set is 1.0\n",
      "The area under ROC for test set is 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(tr_data)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(tt_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fa803688ae8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duecer2/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\", line 42, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'StringIndexer' object has no attribute '_java_obj'\n",
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fa803688ae8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duecer2/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\", line 42, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'StringIndexer' object has no attribute '_java_obj'\n",
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fa803688ae8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duecer2/anaconda3/lib/python3.7/site-packages/pyspark/ml/wrapper.py\", line 42, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'StringIndexer' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['artist',\n",
       " 'auth',\n",
       " 'firstName',\n",
       " 'gender',\n",
       " 'itemInSession',\n",
       " 'lastName',\n",
       " 'length',\n",
       " 'level',\n",
       " 'location',\n",
       " 'method',\n",
       " 'page',\n",
       " 'registration',\n",
       " 'sessionId',\n",
       " 'song',\n",
       " 'status',\n",
       " 'ts',\n",
       " 'userAgent',\n",
       " 'userId',\n",
       " 'lengthIndex',\n",
       " 'firstNameIndex',\n",
       " 'lastNameIndex',\n",
       " 'userAgentIndex',\n",
       " 'tsIndex',\n",
       " 'itemInSessionIndex',\n",
       " 'pageIndex',\n",
       " 'methodIndex',\n",
       " 'songIndex',\n",
       " 'levelIndex',\n",
       " 'genderIndex',\n",
       " 'userIdIndex',\n",
       " 'registrationIndex',\n",
       " 'artistIndex',\n",
       " 'sessionIdIndex',\n",
       " 'locationIndex',\n",
       " 'authIndex',\n",
       " 'statusIndex']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = indexer.fit(paid)\n",
    "indexed = model.transform(paid)\n",
    "indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx =  StringIndexer(inputCol=\"sessionIdIndex\", outputCol=\"sessionId_label\")\n",
    "m1 = label_stringIdx.fit(indexed)\n",
    "m1 = m1.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipeline = Pipeline(stages = [indexer, vecAssembler, sizeHint, kMeans])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
